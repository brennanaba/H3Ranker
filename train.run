#!/bin/bash
#SBATCH -J brennan_test                     # Job name
#SBATCH -A opig                         # Project Account
#SBATCH --time=0-00:20:00                 # Walltime
#SBATCH --cpus-per-task=1
#SBATCH --mem=10000              # total memory (in MB) ### commented out
#SBATCH --gres=gpu:1
#SBATCH --ntasks=1                      # 1 tasks
#SBATCH --nodes=1                       # number of nodes
#S BATCH --workdir=/data/localhost/not-backed-up/kenyon # From where you want the job to be run
#SBATCH --mail-user=brennan.abanadeskenyon@stx.ox.ac.uk  # set email address  - please change to your own, unless you want to make Fergus angry
#SBATCH --mail-type=begin               # Instead only email when job begins...
#SBATCH --partition=naga-gpu-small    # Select a specific partition rather than default
#SBATCH -w nagagpu01.cpu.stats.ox.ac.uk # Provide a specific node/nodelist rather than the standard nodelist associated with the partition (useful if you have a data setup on one specific node)         
#SBATCH --output=/data/localhost/not-backed-up/kenyon/slurm_%j.out  # Writes standard output to this file. %j is jobnumber                             
#SBATCH --error=/data/localhost/not-backed-up/kenyon/slurm_%j.out   # Writes error messages to this file. %j is jobnumber


cd /data/localhost/not-backed-up/kenyon/H3Ranker
source envH3/bin/activate
git pull
pip install .
pip install tensorflow==2.0.0
pip install tensorflow-gpu==2.0.0
chmod 775 H3Ranker/train.py
echo "Working Directory:" > output.out
pwd >> output.out
echo "Installed dependencies:" >> output.out
pip list >> output.out
python H3Ranker/train.py >> output.out 2>&1 && mail -s "Latest Results" kenyon@stats.ox.ac.uk < output.out || mail -s "Error Message" kenyon@stats.ox.ac.uk < output.out
